{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_오차역전파법.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 단순한 계층 구현하기"
      ],
      "metadata": {
        "id": "RdXpI_ftmx-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.1 곱셈 계층"
      ],
      "metadata": {
        "id": "SVT8qf-Jm348"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apoGtwrOmvpX"
      },
      "outputs": [],
      "source": [
        "class MulLayer:\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    out = x * y\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * self.y\n",
        "    dy = dout * self.x\n",
        "\n",
        "    return dx, dy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apple = 100\n",
        "apple_num = 2\n",
        "tax = 1.1\n",
        "\n",
        "# layers\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# forward\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
        "price = mul_tax_layer.forward(apple_price, tax)\n",
        "\n",
        "print(price)"
      ],
      "metadata": {
        "id": "_6H_aVgFngZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backward\n",
        "dprice = 1\n",
        "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
        "print(dapple, dapple_num, dtax)"
      ],
      "metadata": {
        "id": "JY60xLoyn5GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.2 덧셈 계층"
      ],
      "metadata": {
        "id": "Hvtp84OvoiXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AddLayer:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    out = x + y\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * 1\n",
        "    dy = dout * 1\n",
        "    return dx, dy"
      ],
      "metadata": {
        "id": "021frIWrolcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple = 100\n",
        "apple_num = 2\n",
        "orange = 150\n",
        "orange_num = 3\n",
        "tax = 1.1\n",
        "\n",
        "# layers\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_orange_layer = MulLayer()\n",
        "add_apple_orange_layer = AddLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# forward\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
        "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
        "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
        "price = mul_tax_layer.forward(all_price, tax)\n",
        "\n",
        "print(price)\n",
        "\n",
        "# backward\n",
        "dprice = 1\n",
        "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
        "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
        "\n",
        "print(price)\n",
        "print(dapple_num, dapple, dorange, dorange_num, dtax)"
      ],
      "metadata": {
        "id": "5kmUMUDJpCAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 활성화 함수 계층 구현하기"
      ],
      "metadata": {
        "id": "GsZJO3zVqSsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5.1 ReLU 계층"
      ],
      "metadata": {
        "id": "M-w30ug9qVom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "  def __init__(self):\n",
        "    self.mask = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    self.mask = (x <= 0)\n",
        "    out = x.copy()\n",
        "    out[self.mask] = 0\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dout[self.mask] = 0\n",
        "    dx = dout\n",
        "\n",
        "    return dx"
      ],
      "metadata": {
        "id": "YRaCLVu5qY3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
        "print(x)"
      ],
      "metadata": {
        "id": "V7Vy5hEQq9A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (x<=0)\n",
        "print(mask)"
      ],
      "metadata": {
        "id": "HXmwqFIxrGE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (x>0)\n",
        "print(mask)"
      ],
      "metadata": {
        "id": "7PPKHDE-rYnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5.2 Sigmoid 계층"
      ],
      "metadata": {
        "id": "Fsa0BsVtr3St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.out = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = 1 / ( 1 + np.exp(-x))\n",
        "    self.out = out\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "    return dx"
      ],
      "metadata": {
        "id": "1_cicFs5r5sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6 Affine / Softmax 계층 구현하기"
      ],
      "metadata": {
        "id": "nbQm9P5GsUM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.1 Affine 계층"
      ],
      "metadata": {
        "id": "2Son2-fzsaN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        \n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 편향 매개변수의 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        \n",
        "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
        "        return dx"
      ],
      "metadata": {
        "id": "xC6XAFivsX8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.6.2 Softmax-with-Loss 계층"
      ],
      "metadata": {
        "id": "mFb-vpiEtPU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n"
      ],
      "metadata": {
        "id": "5aHkJumMwDQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "metadata": {
        "id": "KndT-kMxwNd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithLoss:\n",
        "  def __init__(self):\n",
        "    self.loss = None\n",
        "    self.y = None\n",
        "    self.t = None\n",
        "\n",
        "  def forward(self, x, t):\n",
        "    self.t = t\n",
        "    self.y = softmax(x)\n",
        "    self.loss = cross_entropy_error(self.y, self.t)\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "        \n",
        "        return dx"
      ],
      "metadata": {
        "id": "aYHp-oaBtU1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.7 오차역전파법 구현하기\n",
        "- 미니배치\n",
        "- 기울기 산출\n",
        "- 매개변수 갱신\n",
        "- 반복"
      ],
      "metadata": {
        "id": "cAk6j3n3vsHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.7.1 오차역전파법을 적용한 신경망 구현"
      ],
      "metadata": {
        "id": "UMVJB1cKwaJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = tmp_val + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val\n",
        "        it.iternext()   \n",
        "        \n",
        "    return grad"
      ],
      "metadata": {
        "id": "DR-yFmjhxeMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = ReLU()\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "        \n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "        \n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "        \n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "        \n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads"
      ],
      "metadata": {
        "id": "LEt8HKMSv05b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.7.2 오차역전파법으로 구한 기울기 검증"
      ],
      "metadata": {
        "id": "bGz1u5kFwcPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "x_batch = x_train[:3]\n",
        "t_batch = t_train[:3]\n",
        "\n",
        "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
        "grad_backprop = network.gradient(x_batch, t_batch)\n",
        "\n",
        "for key in grad_numerical.keys():\n",
        "  #print(grad_backprop[key])\n",
        "  #print(grad_numerical[key])\n",
        "  diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
        "  print(key + \":\" + str(diff))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yxSKNuPxj1t",
        "outputId": "7b979542-1ef6-4e1c-851e-30baae9d3761"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1:4.797764011236256e-10\n",
            "b1:2.9549393546889762e-09\n",
            "W2:5.339874326528669e-09\n",
            "b2:1.4035142591878325e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.7.3 오차역전파법을 사용한 학습 구현"
      ],
      "metadata": {
        "id": "HugfWf7RwjXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 오차역전파법으로 기울기 구함\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "    \n",
        "    # 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "    \n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf9O_A4zYj6y",
        "outputId": "0d585261-6b2d-4768-c431-e7bba00b404b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08736666666666666 0.0862\n",
            "0.9023333333333333 0.9058\n",
            "0.9232833333333333 0.9244\n",
            "0.9369166666666666 0.9377\n",
            "0.9442333333333334 0.941\n",
            "0.9515166666666667 0.9488\n",
            "0.9558 0.9527\n",
            "0.9593166666666667 0.9543\n",
            "0.96255 0.9544\n",
            "0.9663166666666667 0.9606\n",
            "0.9694333333333334 0.9628\n",
            "0.9710833333333333 0.9642\n",
            "0.97265 0.9651\n",
            "0.9749833333333333 0.9659\n",
            "0.97605 0.9666\n",
            "0.9776666666666667 0.9675\n",
            "0.9781333333333333 0.9692\n"
          ]
        }
      ]
    }
  ]
}